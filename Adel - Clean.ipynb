{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "material-cross",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "herbal-tsunami",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered S3 methods overwritten by 'ggplot2':\n",
      "  method         from \n",
      "  [.quosures     rlang\n",
      "  c.quosures     rlang\n",
      "  print.quosures rlang\n",
      "Registered S3 method overwritten by 'rvest':\n",
      "  method            from\n",
      "  read_xml.response xml2\n",
      "-- Attaching packages --------------------------------------- tidyverse 1.2.1 --\n",
      "v ggplot2 3.1.1       v purrr   0.3.2  \n",
      "v tibble  2.1.1       v dplyr   0.8.0.1\n",
      "v tidyr   0.8.3       v stringr 1.4.0  \n",
      "v readr   1.3.1       v forcats 0.4.0  \n",
      "-- Conflicts ------------------------------------------ tidyverse_conflicts() --\n",
      "x dplyr::filter() masks stats::filter()\n",
      "x dplyr::lag()    masks stats::lag()\n",
      "\n",
      "Attaching package: 'gridExtra'\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    combine\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training <- read.csv('train.csv')\n",
    "test <- read.csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(gridExtra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exposed-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentRightTurn <- function(dataset) {\n",
    "    isRightTurn <- function(entry, exit) {\n",
    "        rightexit <- list(\n",
    "            N = c(\"NW\", \"W\", \"SW\"),\n",
    "            NW = c(\"W\", \"SW\", \"S\"),\n",
    "            W = c(\"SW\", \"S\", \"SE\"),\n",
    "            SW = c(\"S\", \"SE\", \"E\"),\n",
    "            S = c(\"SE\", \"E\", \"NE\"),\n",
    "            SE = c(\"E\", \"NE\", \"N\"),\n",
    "            E = c(\"NE\", \"N\", \"NW\"),\n",
    "            NE = c(\"N\", \"NW\", \"W\")\n",
    "        )\n",
    "        exit %in% rightexit[[entry]]\n",
    "    }\n",
    "    vIsRightTurn <- Vectorize(isRightTurn)\n",
    "    dataset %>% \n",
    "        mutate(RightTurn = vIsRightTurn(EntryHeading, ExitHeading)) %>%\n",
    "        group_by(IntersectionId, EntryHeading) %>%\n",
    "        summarize(RightTurnAllowed = max(RightTurn)) %>%\n",
    "        inner_join(dataset) %>%\n",
    "        mutate(RightTurn = ifelse(vIsRightTurn(EntryHeading, ExitHeading), 1, 0))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "endangered-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentLeftTurn <- function(dataset) {\n",
    "    isLeftTurn <- function(entry, exit) {\n",
    "        leftexit <- list(\n",
    "            N = c(\"NE\", \"E\", \"SE\"),\n",
    "            NW = c(\"N\", \"NE\", \"E\"),\n",
    "            W = c(\"NW\", \"N\", \"NE\"),\n",
    "            SW = c(\"W\", \"NW\", \"N\"),\n",
    "            S = c(\"SW\", \"W\", \"NW\"),\n",
    "            SE = c(\"S\", \"SW\", \"W\"),\n",
    "            E = c(\"SE\", \"S\", \"SW\"),\n",
    "            NE = c(\"E\", \"SE\", \"S\")\n",
    "        )\n",
    "        exit %in% leftexit[[entry]]\n",
    "    }\n",
    "    vIsLeftTurn <- Vectorize(isLeftTurn)\n",
    "    dataset %>% \n",
    "        mutate(LeftTurn = vIsLeftTurn(EntryHeading, ExitHeading)) %>%\n",
    "        group_by(IntersectionId, EntryHeading) %>%\n",
    "        summarize(LeftTurnAllowed = max(LeftTurn)) %>%\n",
    "        inner_join(dataset) %>%\n",
    "        mutate(LeftTurn = ifelse(vIsLeftTurn(EntryHeading, ExitHeading), 1, 0))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-nurse",
   "metadata": {},
   "source": [
    "## Transformations and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "oriented-lodging",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Joining, by = c(\"IntersectionId\", \"EntryHeading\")\n",
      "Joining, by = c(\"IntersectionId\", \"EntryHeading\")\n"
     ]
    }
   ],
   "source": [
    "augTraining <- augmentRightTurn(training)\n",
    "augTraining <- augmentLeftTurn(augTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "geological-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformedTrain <- augTraining %>% select(IntersectionId,LeftTurnAllowed, RightTurnAllowed, RightTurn, LeftTurn, Latitude,Longitude,EntryHeading,ExitHeading,Hour,Weekend,Month,City,TimeFromFirstStop_p50,DistanceToFirstStop_p50, TotalTimeStopped_p50)\n",
    "\n",
    "transformedTrain <- transformedTrain %>% mutate(\n",
    "    JanAndMay = ifelse(Month == 1 | Month == 5, 1, 0),\n",
    "    straightThrough = ifelse(EntryHeading == ExitHeading, 1, 0),\n",
    "    rushHour = ifelse((Hour >= 6 & Hour <= 9) | (Hour >= 15 & Hour <= 18), 1, 0),\n",
    "    hasWaitTime = ifelse(DistanceToFirstStop_p50 > 0 & TimeFromFirstStop_p50 > 0, 1, 0),\n",
    "    LogTotalTimeStopped_p50 = ifelse(hasWaitTime == 1, log(TotalTimeStopped_p50), TotalTimeStopped_p50),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-tenant",
   "metadata": {},
   "source": [
    "## Supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "pending-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#' @description\n",
    "#' Find group position for each elment of a vector\n",
    "#'\n",
    "#' @param values vector which should values that depends on the group\n",
    "#' @param groupValues group values in the vector (hopefully unique)\n",
    "#' @param tolerance for matching equality\n",
    "#'\n",
    "#' @return group membership for each element of the vector 'values'\n",
    "#'\n",
    "FindUniquePos=function(values,groupValues,tolerance=1.e-5)\n",
    "{ ngroup = length(groupValues) # number of groups\n",
    "temp = unique(groupValues)\n",
    "if(length(temp)<ngroup)\n",
    "{ cat(\"Won't work: non-unique group values\\n\"); return(0); }\n",
    "npred = length(values)\n",
    "group = rep(0,ngroup) # initialize as group 0\n",
    "for(i in 1:ngroup)\n",
    "{ #group[values==groupValues[i]]=i\n",
    "igroup = (abs(values-groupValues[i])<tolerance)\n",
    "group[igroup] = i # group label according to position in groupValues\n",
    "}\n",
    "if( any(group==0) ) cat(\"Warning: some values not matched to groupValues\\n\")\n",
    "group\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "authorized-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#' interval score function for prediction intervals,\n",
    "#' smaller value is better\n",
    "#'\n",
    "#' @description\n",
    "#' interval score for prediction intervals\n",
    "#'\n",
    "#' @param predobj has 3 (or more) columns: pointprediction, predLB, predUB\n",
    "#' @param actual vector of actual values (in holdout set, for example)\n",
    "#' @param alpha level for prediction interval,\n",
    "#' 1-alpha is expected coverage proportion if model is valid;\n",
    "#' alpha=0.2 for 80% prediction intervals\n",
    "#'\n",
    "#' @return interval score\n",
    "#'\n",
    "intervalScore=function(predObj,actual,alpha)\n",
    "{ n=nrow(predObj)\n",
    "    ilow=(actual<predObj[,2]) # underestimation\n",
    "    ihigh=(actual>predObj[,3]) # overestimation\n",
    "    imid= (!ilow & !ihigh)\n",
    "    sumlength=sum(predObj[,3]-predObj[,2]) # sum of lengths of prediction intervals\n",
    "    sumlow=sum(predObj[ilow,2]-actual[ilow])*2/alpha\n",
    "    sumhigh=sum(actual[ihigh]-predObj[ihigh,3])*2/alpha\n",
    "    (sumlength+sumlow+sumhigh)/n # average length + average under/over penalties\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-history",
   "metadata": {},
   "source": [
    "## Regression trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chemical-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rpart); library(rpart.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "irish-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "regTree = function(modelWrapper, dataset){\n",
    "    smp_size <- floor(0.75 * nrow(dataset))\n",
    "    train_ind <- sample(seq_len(nrow(dataset)), size = smp_size)\n",
    "\n",
    "    train <- dataset[train_ind, ]\n",
    "    holdo <- dataset[-train_ind, ]\n",
    "    \n",
    "    RegTree <- modelWrapper(train)\n",
    "    \n",
    "    meanByTNode=tapply(train$TotalTimeStopped_p50,RegTree$where,mean)\n",
    "    # 50% predictions\n",
    "    Q1ByTNode=tapply(train$TotalTimeStopped_p50,RegTree$where,quantile,prob=0.25)\n",
    "    Q2ByTNode=tapply(train$TotalTimeStopped_p50,RegTree$where,median)\n",
    "    Q3ByTNode=tapply(train$TotalTimeStopped_p50,RegTree$where,quantile,prob=0.75)\n",
    "    ByTNode=cbind(meanByTNode,Q1ByTNode,Q3ByTNode,Q2ByTNode)\n",
    "    # 80% predictions\n",
    "    Q180ByTNode=tapply(train$TotalTimeStopped_p50,RegTree$where,quantile,prob=0.1)\n",
    "    Q280ByTNode=tapply(train$TotalTimeStopped_p50,RegTree$where,median)\n",
    "    Q380ByTNode=tapply(train$TotalTimeStopped_p50,RegTree$where,quantile,prob=0.9)\n",
    "    By80TNode=cbind(meanByTNode,Q180ByTNode,Q380ByTNode,Q280ByTNode)\n",
    "    meanpredRegTree=predict(RegTree,newdata=holdo,type=\"vector\")\n",
    "    \n",
    "    TNodeGroup=FindUniquePos(meanpredRegTree,meanByTNode)\n",
    "    \n",
    "    Q1predRegTree=Q1ByTNode[TNodeGroup]\n",
    "    Q3predRegTree=Q3ByTNode[TNodeGroup]\n",
    "    predIntRegTree=cbind(meanpredRegTree,Q1predRegTree,Q3predRegTree)\n",
    "\n",
    "    Q180predRegTree=Q180ByTNode[TNodeGroup]\n",
    "    Q380predRegTree=Q380ByTNode[TNodeGroup]\n",
    "    predInt80RegTree=cbind(meanpredRegTree,Q180predRegTree,Q380predRegTree)\n",
    "    \n",
    "    cat(\"Avg Length | Interval Score | Coverage: Output for 50% prediction interval \\n\")\n",
    "    avglengthTree=mean(predIntRegTree[,3]-predIntRegTree[,2])\n",
    "    ISTree=intervalScore(predIntRegTree,holdo$TotalTimeStopped_p50,0.5)\n",
    "    coverTree=mean(holdo$TotalTimeStopped_p50>=predIntRegTree[,2] & holdo$TotalTimeStopped_p50<=predIntRegTree[,3])\n",
    "    cat(\"Reg:\", avglengthTree,ISTree,coverTree,\"\\n\")\n",
    "    \n",
    "    cat(\"Avg Length | Interval Score | Coverage: Output for 80% prediction interval \\n\")\n",
    "    avglengthTree80=mean(predInt80RegTree[,3]-predInt80RegTree[,2])\n",
    "    ISTree80=intervalScore(predInt80RegTree,holdo$TotalTimeStopped_p50,0.2)\n",
    "    coverTree80=mean(holdo$TotalTimeStopped_p50>=predInt80RegTree[,2] & holdo$TotalTimeStopped_p50<=predIntRegTree[,3])\n",
    "    cat(\"Reg:\", avglengthTree80,ISTree80,coverTree80,\"\\n\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "major-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "basicRegressionTreeModelWrapper <- function(data){\n",
    "    rpart(TotalTimeStopped_p50~LeftTurnAllowed+RightTurnAllowed+hasWaitTime+rushHour+straightThrough+Weekend+JanAndMay+City+RightTurn+LeftTurn, data=data, cp=0.0001, maxdepth= 6, minsplit=3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "interpreted-internet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Length | Interval Score | Coverage: Output for 50% prediction interval \n",
      "Reg: 6.371841 12.85141 0.848592 \n",
      "Avg Length | Interval Score | Coverage: Output for 80% prediction interval \n",
      "Reg: 12.38162 18.50328 0.8990317 \n"
     ]
    }
   ],
   "source": [
    "r1 = regTree(basicRegressionTreeModelWrapper, transformedTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-owner",
   "metadata": {},
   "source": [
    "## Quantile Regression Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "direct-newton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'quantregForest' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\Alvi\\AppData\\Local\\Temp\\Rtmpw7EWt3\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'quantregForest' was built under R version 3.6.3\"Loading required package: randomForest\n",
      "randomForest 4.6-14\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Attaching package: 'randomForest'\n",
      "\n",
      "The following object is masked from 'package:gridExtra':\n",
      "\n",
      "    combine\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    combine\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    margin\n",
      "\n",
      "Loading required package: RColorBrewer\n"
     ]
    }
   ],
   "source": [
    "#install.packages(\"quantregForest\")\n",
    "library(quantregForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "alert-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervalScorePlus=function(predObj,actual,alpha)\n",
    "{ \n",
    "    n=nrow(predObj)\n",
    "    ilow=(actual<predObj[,2]) # underestimation\n",
    "    ihigh=(actual>predObj[,3]) # overestimation\n",
    "    sumlength=sum(predObj[,3]-predObj[,2]) # sum of lengths of prediction intervals\n",
    "    sumlow=sum(predObj[ilow,2]-actual[ilow])*2/alpha\n",
    "    sumhigh=sum(actual[ihigh]-predObj[ihigh,3])*2/alpha\n",
    "    avglength=sumlength/n\n",
    "    IS=(sumlength+sumlow+sumhigh)/n # average length + average under/over penalties\n",
    "    cover=mean(actual>= predObj[,2] & actual<=predObj[,3])\n",
    "    summ=c(1-alpha,avglength,IS,cover)\n",
    "    summ\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "unnecessary-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantRegForest = function(dataset){\n",
    "    smp_size <- floor(0.75 * nrow(dataset))\n",
    "    train_ind <- sample(seq_len(nrow(dataset)), size = smp_size)\n",
    "\n",
    "    train <- dataset[train_ind, ]\n",
    "    holdo <- dataset[-train_ind, ]\n",
    "    \n",
    "    logOrgTrain = train %>% select(IntersectionId, LeftTurnAllowed, RightTurnAllowed, City, straightThrough, rushHour, hasWaitTime,JanAndMay,LeftTurn, RightTurn, LogTotalTimeStopped_p50)\n",
    "    orgTrain = train %>% select(IntersectionId, LeftTurnAllowed, RightTurnAllowed, City, straightThrough, rushHour, hasWaitTime, JanAndMay,LeftTurn, RightTurn, TotalTimeStopped_p50)\n",
    "\n",
    "    p=10 # number of explanatory variables\n",
    "    p1=p+1 # variable p+1 will be response variable\n",
    "    \n",
    "    ## remove observations with mising values\n",
    "    logOrgTrain <- logOrgTrain[ !apply(is.na(orgTrain), 1,any), ]\n",
    "    ## number of remining samples\n",
    "    n <- 100000\n",
    "    ## divide into training and test data\n",
    "    indextrain <- sample(1:n,round(0.8*n),replace=FALSE)\n",
    "    logXtrain <- logOrgTrain[ indextrain,2:p]\n",
    "    logXtest <- logOrgTrain[-indextrain,2:p]\n",
    "    logYtrain <- logOrgTrain[ indextrain,p1]\n",
    "    logYtrain = logYtrain[[1]]\n",
    "    logYtest <- logOrgTrain[-indextrain,p1]\n",
    "    \n",
    "    ## remove observations with mising values\n",
    "    orgTrain <- orgTrain[ !apply(is.na(orgTrain), 1,any), ]\n",
    "    Xtrain <- orgTrain[ indextrain,2:p]\n",
    "    Xtest <- orgTrain[-indextrain,2:p]\n",
    "    Ytrain <- orgTrain[ indextrain,p1]\n",
    "    Ytrain = Ytrain[[1]]\n",
    "    Ytest <- orgTrain[-indextrain,p1]\n",
    "    \n",
    "    Xtest = Xtest[1:20000,]\n",
    "    Ytest = Ytest[1:20000,]\n",
    "    logXtest = logXtest[1:20000,]\n",
    "    logYtest = logYtest[1:20000,]\n",
    "    \n",
    "    qrf1 = quantregForest(x=Xtrain,y=Ytrain, mtry=8)\n",
    "    qrf2 = quantregForest(x=logXtrain,y=logYtrain, mtry=8)\n",
    "    \n",
    "    pred1y = predict(qrf1, what=c(.1,.25,.5,.75,.9), newdata=Xtest)\n",
    "    pred2ylog = predict(qrf2, what=c(.1,.25,.5,.75,.9), newdata=logXtest)\n",
    "    \n",
    "    pred2y = pred2ylog\n",
    "    for(row in 1:nrow(pred2ylog)) {\n",
    "        for(col in 1:ncol(pred2ylog)) {\n",
    "            if (pred2ylog[row, col] != 0) {\n",
    "                pred2y[row,col] = exp(pred2ylog[row, col])\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    actual1 = Ytest\n",
    "    actual2=logYtest\n",
    "    for(row in 1:nrow(logYtest)) {\n",
    "        for(col in 1:ncol(logYtest)) {\n",
    "            if (logYtest[row, col] != 0) {\n",
    "                actual2[row,col] = exp(logYtest[row, col])\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    actual2 = actual2[[1]]\n",
    "    actual1 = actual1[[1]]\n",
    "    \n",
    "    IS50qrf1=intervalScorePlus(pred1y[,c(3,2,4)],actual1,0.5)\n",
    "    IS80qrf1=intervalScorePlus(pred1y[,c(3,1,5)],actual1,0.2)\n",
    "    summaryTable=rbind(IS50qrf1,IS80qrf1)\n",
    "    rownames(summaryTable)=c(\"trained on y\",\"trained on y\")\n",
    "    colnames(summaryTable)=c(\"level\",\"avglen\",\"intervalScore\",\"coverage\")\n",
    "    print(summaryTable)\n",
    "    \n",
    "    IS50qrf2=intervalScorePlus(pred2y[,c(3,2,4)],actual2,0.5)\n",
    "    IS80qrf2=intervalScorePlus(pred2y[,c(3,1,5)],actual2,0.2)\n",
    "    summaryTable2=rbind(IS50qrf2,IS80qrf2)\n",
    "    rownames(summaryTable2)=c(\"trained on log(y)\",\"trained on log(y)\")\n",
    "    colnames(summaryTable2)=c(\"level\",\"avglen\",\"intervalScore\",\"coverage\")\n",
    "    print(summaryTable2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "foster-february",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             level   avglen intervalScore coverage\n",
      "trained on y   0.5  6.36705      12.94760  0.85095\n",
      "trained on y   0.8 12.12758      18.75238  0.93870\n",
      "                  level    avglen intervalScore coverage\n",
      "trained on log(y)   0.5  6.359547      45.49245  0.85180\n",
      "trained on log(y)   0.8 12.187747     100.07553  0.93925\n"
     ]
    }
   ],
   "source": [
    "qrf = quantRegForest(transformedTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-metabolism",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
